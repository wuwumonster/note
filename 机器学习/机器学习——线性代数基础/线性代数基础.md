# 坐标与变换

## 描述空间的工具——向量

直观的说将一组数字排列成一列护额一行，就称为向量

一个简单的二维向量 $\left[ \begin{matrix} 4 \\ 5 \end{matrix} \right]$ 可以理解为二维平面中x坐标为4，y坐标为5的一个点，也可以理解为以(0,0)为起点，以(4,5)为终点的一条有向线段

进一步推广可以有三维向量，n维向量取决于向量中的成分数量

### 通常使用列向量

列向量在后续的向量坐标变换、空间之间的映射等计算过程的处理

列向量的生成

使用了二维数组的初始化方法，所以语句中对嵌套了一层中括号，就可以通过行向量转置的方法来生成对应列向量

![Untitled](%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%9F%BA%E7%A1%80%204ef343cc691b4832a76ee547aaaec7dd/Untitled.png)

### 向量加法

![Untitled](%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%9F%BA%E7%A1%80%204ef343cc691b4832a76ee547aaaec7dd/Untitled%201.png)

### 向量的数量乘法

![Untitled](%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%9F%BA%E7%A1%80%204ef343cc691b4832a76ee547aaaec7dd/Untitled%202.png)

### 向量间的乘法：内积和外积

****内积：****

$u \cdot v = \left[ \begin{matrix} u_1 \\ u_2 \\ u_3 \\ ... \\u_n \end{matrix} \right] \cdot \left[ \begin{matrix} v_1 \\ v_2 \\ v_3 \\ ... \\v_n \end{matrix} \right] = u_1v_1 + u_2v_2 + u_3v_3 + ... + u_nv_n$

$u \cdot v = \text{\textbar}u\text{\textbar}\cdot\text{\textbar}v\text{\textbar}cos \theta$

物理意义向量u在向量v上的投影长度乘以向量v的模长

> 如果v是单位向量，内积就可以直接描述为向量u在向量v上的投影长度
> 

例如计算向量 $u=\left[ \begin{matrix} 3 \\ 5 \\  2\end{matrix} \right]$和 $v=\left[ \begin{matrix} 1 \\ 4 \\ 7 \end{matrix} \right]$的内积运算结果

![Untitled](%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%9F%BA%E7%A1%80%204ef343cc691b4832a76ee547aaaec7dd/Untitled%203.png)

用二维数组的列向量或行向量进行内积运算是不可以的

因为在这种方式下的向量本质上是矩阵，如果将这种状态下的向量作为内积运算函数dot的参数，那么就需要依据矩阵的乘法法则来进行计算

![Untitled](%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%9F%BA%E7%A1%80%204ef343cc691b4832a76ee547aaaec7dd/Untitled%204.png)

****外积：****

运算法则

$u \times v = \left[ \begin{matrix} u_1 \\  u_2 \end{matrix} \right] \times \left[ \begin{matrix} v_1 \\ v_@\end{matrix} \right] = u_1v_2 - u_2v_1$

 $u \times v = \text{\textbar}u\text{\textbar}\cdot\text{\textbar}v\text{\textbar}sin \theta$za

在二维平面中，向量的外积表示两个向量张成的平行四边形的“面积”，当两向量的夹角大于180度，所得结果为负

例：计算 $u=\left[ \begin{matrix} 3 \\ 5 \end{matrix} \right]$和 $u=\left[ \begin{matrix} 1 \\4\end{matrix} \right]$的外积运算结果

![Untitled](%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%9F%BA%E7%A1%80%204ef343cc691b4832a76ee547aaaec7dd/Untitled%205.png)

三维向量的运算法则

$u \times v = \left[ \begin{matrix} u_1 \\ u_2 \\ u_3\end{matrix} \right] \times \left[ \begin{matrix} v_1 \\ v_2 \\ v_3\end{matrix} \right] = \left[ \begin{matrix} u_2v_3 - u_3v_2 \\ u_3v_1 - u_1v_3 \\ u_1v_2 - u_2v_1\end{matrix} \right]$

![Untitled](%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%9F%BA%E7%A1%80%204ef343cc691b4832a76ee547aaaec7dd/Untitled%206.png)

### 先数乘后叠加：向量的线性组合

$cu + dv + ew = c\left[ \begin{matrix} u_1 \\ u_2 \\ u_3\end{matrix} \right] + d \left[ \begin{matrix} v_1 \\ v_2 \\ v_3\end{matrix} \right] +e\left[ \begin{matrix} w_1 \\ w_2 \\ w_3\end{matrix} \right]= \left[ \begin{matrix} cu_1 +dv_1 +ew_1 \\ cu_2 +dv_2 +ew_2 \\ cu_3 +dv_3 +ew_3\end{matrix} \right]$li

例： $u=\left[ \begin{matrix} 1 \\ 2 \\ 3\end{matrix} \right]$ ,$v=\left[ \begin{matrix} 4 \\ 5 \\ 6\end{matrix} \right]$, $w=\left[ \begin{matrix} 7 \\ 8 \\ 9\end{matrix} \right]$即，3u+4v+5w

![Untitled](%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%9F%BA%E7%A1%80%204ef343cc691b4832a76ee547aaaec7dd/Untitled%207.png)

三个非零的三维向量有三种不同的线性组合情况

**第一种**

cu的所有线性组合构成的图像

由于c可以取零，因此cu的所有线性组合构成的像可以表示为三维空间中一条穿过原点（0,0,0）的直线，包括原点本身

**第二种**

cu+dv的所有线性组合构成的图像

- 当向量u和向量v不在一条直线 上时，cu+dv的所有线性组合构成的图像可以表示为三维空间中的一个通过原点（0,0,0）的二维平面
- 当向量u和向量v处于一条直线上时，cu+dv的所有线性组合构成的图像退化成情况一

********************第三种********************

cu+dv+ew的所有线性组合构成的图像

- 向量u，v，w不在一个平面上时，cu+dv+ew的所有线性组合构成的图像是整个三维空间
- 向量u，v，w处于一个平面上时，退化为情况二
- 向量u，v，w处于一条直线上时，退化为情况一

## 基底构建一切，基底决定坐标

### 向量的坐标依赖于选取的基底

在通常意义上默认以方向为x轴，y轴的正方向，长度为1的两个向量来作为讨论的基准，

即 $e_x = \left[ \begin{matrix} 1 \\ 0 \end{matrix} \right] , e_y =\left[ \begin{matrix} 0 \\ 1 \end{matrix} \right]$

对向量u的完整准确说法是，在基底 $(e_x,e_y)$，其坐标是 $\left[ \begin{matrix} 3 \\ 5 \end{matrix} \right]$ 

### 构成基底的条件

在n维空间中，任意一个向量都可以表示为这一组基向量的线性组合，并且这种线性组合的表示方式（也就是系数）必须是唯一的

- 向量数量足够
- 满足线性无关

### 张成空间

对于一组向量，由它的所有线性组合所构成的空间就称为这一组向量的张成空间

## 矩阵

一个矩阵是一个m $\times$n的数字方阵，可以看作是n个m维列向量从左向右并排摆放，也可以看作是m个n维行向量从上向下叠放

### 特殊形态的矩阵

- 方阵 行数和列数相等的一类方阵
- 转置与对称矩阵
    - 转置
    行和列的互换，就是矩阵的转置，原矩阵A的转置矩阵称为 $A^T$
    - 对称
    原矩阵和转置后的矩阵相等，那么这个矩阵就是对称矩阵，前提条件
        - 是一个方阵
        - S方阵中满足 $S_{ij}=S_{ji}$
- 零矩阵 所有元素为0的矩阵，记作 $O$
可通过下标描述矩阵大小如 $5 \times 3$的零矩阵为 $O_{5,3}$
- 对角矩阵 在非对角线上矩阵的元素全为零
- 单位矩阵  对角位置上元素均为1，其余位置均为0

### 矩阵乘以向量：改变向量的空间位置

将向量看作一个列数为1的特殊矩阵

**运算过程：**

- 矩阵在左，列向量在右，矩阵的列数和列向量的维数必须相等
- 矩阵和列向量相乘的结果也是一个列向量
- 矩阵的行数就是结果向量的维数
- 乘法运算的实施过程就是矩阵的每行和列向量的对应元素相乘后再进行相加

### 矩阵乘向量的新视角：变换基底

**************************************************************列的角度：重新组合矩阵的列向量**************************************************************

一个矩阵和一个列向量相乘的过程可以理解为对于原矩阵各列的列向量重新进行线性组合的过程，

而在线性组合的运算过程中，结果中各个系数就是参与乘法运算的列向量中对应的各个成分

# 空间与映射

## 矩阵

### 矩阵表示的空间映射

由于矩阵乘法的作用，原始向量的空间位置甚至其所在空间的维度和形态都发生了改变，这就是矩阵乘法的空间映射作用

### 降维，“矮胖”矩阵对空间的压缩

对于m行n列的矩阵A，当m<n时，矩阵A的行数小于列数。对于这种矩阵通俗的说就是一个“矮胖”的矩阵，l列向量 $x$ 是n维空间 $R^n$ 中的一个n维向量，向量 $x$的n个默认基向量 $(e_1,e_2,e_3,…,e_n)$分别被矩阵A映射成了n个m维的向量

因为m<n这一组向量所能张成空间的维数最大就是m，这样一来在矩阵的乘法作用下，位于n维空间 $R^n$ 中的任意向量 $x$ 经过映射后，都被转换到了一个维度更低的新空间的新位置上

> 在满足 $m<n$的情况下，“矮胖”矩阵 $A$压缩了原始空间 $R^n$
> 

 例如一个 $2 \times 3$的实际矩阵A，映射后的目标向量

- 三个二维目标向量满足不全部共线，那么其所有的线性组合结果就能构成一个二维平面 $R^2$。经过矩阵 A 的映射，整个原始二维向量空间 $R^3$就被压缩成了一个二维平面
- 如果三个二维向量是共线向量，即三者都在同一条直线上，那么其线性组合就只能分布在二维平面 $R^2$中的一条穿过原点(0,0)直线上